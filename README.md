# Fine Tuning LoRA aplicado a TripoSR

<a href="https://huggingface.co/stabilityai/TripoSR"><img src="https://img.shields.io/badge/ğŸ”—%20TripoSR-HuggingFace-orange"></a>
<a href="https://arxiv.org/pdf/2403.02151"><img src="https://img.shields.io/badge/ğŸ“„%20Paper%20TripoSR-ArXiv-B31B1B"></a>
<a href="/mnt/data/CVProjectPresent.pdf"><img src="https://img.shields.io/badge/ğŸ“˜%20Informe%20del%20Proyecto-PDF-blue"></a>

---

## ğŸ“Œ DescripciÃ³n

Este proyecto desarrolla un **Fine-Tuning con LoRA sobre el modelo TripoSR** para mejorar la reconstrucciÃ³n 3D a partir de imÃ¡genes especÃ­ficas del dataset utilizado.  
El objetivo fue **especializar el modelo en ciertas formas, texturas o configuraciones**, obteniendo mejores *scene codes* y posteriormente mallas `.obj` adaptadas al dominio del proyecto.

### Â¿QuÃ© se modificÃ³ exactamente con LoRA?

El entrenamiento LoRA se aplicÃ³ sobre:

- **El backbone** del encoder de imagen de TripoSR.  
- Los **mÃ³dulos de atenciÃ³n**, especÃ­ficamente los valores **K, V y C** dentro de las capas *self-attention* y *cross-attention* del modelo.

Esto permite que el modelo aprenda nuevas variaciones de forma **sin modificar todos los pesos base**, manteniendo estable la arquitectura principal.

Durante el fine-tuning se inyectaron los mÃ³dulos LoRA en:

- `transformer_blocks[i].attn1.to_q`
- `transformer_blocks[i].attn1.to_k`
- `transformer_blocks[i].attn1.to_v`
- `transformer_blocks[i].attn1.to_out.0`
- `transformer_blocks[i].attn2.to_q`
- `transformer_blocks[i].attn2.to_k`
- `transformer_blocks[i].attn2.to_v`
- `transformer_blocks[i].attn2.to_out.0`

(Ver lÃ³gica en `fine_tuning.py` del proyecto).

---

## âš™ï¸ Detalles tÃ©cnicos  
### Cambios realizados al modelo TripoSR original

La Ãºnica modificaciÃ³n directa hecha al cÃ³digo fuente de TripoSR ocurriÃ³ en:

```bash
tsr/models/nerf_renderer.py
```

### Â¿QuÃ© se cambiÃ³?

Se aÃ±adiÃ³ un parÃ¡metro **`chunk_size`** para controlar la cantidad de rayos procesados en cada iteraciÃ³n del renderizado NeRF.

### Â¿Por quÃ© es necesario?

TripoSR extrae la malla usando **Marching Cubes**, que requiere muestrear la funciÃ³n SDF sobre un grid 3D. Esto puede consumir **enormes cantidades de VRAM**.  
El `chunk_size` permite dividir este procesamiento en bloques mÃ¡s pequeÃ±os para:

- evitar *OOM errors* (out of memory),
- permitir el entrenamiento en GPUs de 24â€“48 GB de VRAM,
- mejorar la estabilidad del entrenamiento LoRA,
- mantener el *rendering pipeline* sin romper la arquitectura interna.

Esta modificaciÃ³n **no altera la arquitectura del modelo**, solo la eficiencia computacional.

---

## ğŸ› ï¸ InstalaciÃ³n y configuraciÃ³n del entorno

### âš ï¸ Requisitos mÃ­nimos de hardware
| Recurso | Valor mÃ­nimo |
|--------|--------------|
| GPU | **CUDA 11.x**, ideal 11.4 |
| VRAM | **â‰¥ 25 GB** (para fine-tuning) |
| RAM | 16 GB |
| Sistema | Linux, CentOS7, Ubuntu 20.04 |
| Python | 3.9.x |

---

## ğŸ“¥ InstalaciÃ³n paso a paso (Conda + CUDA + TorchMCubes)

### 1ï¸âƒ£ Crear entorno conda  
*(El comando exacto depende del usuario)*

```bash
conda create -n TripoSR python=3.9
conda activate TripoSR
```

---

### 2ï¸âƒ£ Instalar PyTorch compatible con CUDA 11.8

```bash
pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu118
```

---

### 3ï¸âƒ£ Instalar dependencias del proyecto

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Fijar NumPy a la versiÃ³n correcta

```bash
pip install "numpy==1.26.4" --force-reinstall
python -c "import numpy as np; print('numpy', np.__version__)"
```

---

### 5ï¸âƒ£ Instalar TorchMCubes

```bash
pip install --no-build-isolation "torchmcubes @ git+https://github.com/tatsy/torchmcubes.git"
```

Si falla:

```bash
pip install --upgrade pip
unzip torchmcubes
cd torchmcubes
pip install -e .
```

---

### 6ï¸âƒ£ Instalar herramientas para compilaciÃ³n

```bash
pip install -U pip setuptools wheel
pip install -U scikit-build-core ninja cmake
```

---

### 7ï¸âƒ£ Cargar mÃ³dulos del clÃºster (HPC)

```bash
module purge all
module load gnu9
module load cuda/11.4
```

---

### 8ï¸âƒ£ ValidaciÃ³n final

```bash
python -c "import torch, torchmcubes, numpy as np; print('CUDA available?', torch.cuda.is_available()); print('ok torchmcubes, numpy', np.__version__)"
```

---

## ğŸš€ Uso del proyecto

A continuaciÃ³n se explica cÃ³mo ejecutar **fine_tuning.py** y luego **inference_lora.py**.

---

# ğŸ¯ Fine Tuning (Entrenamiento LoRA)

Archivo: **fine_tuning.py**

### EjecuciÃ³n general:

```bash
python fine_tuning.py     --input_folder ruta/a/imagenes/     --output_dir outputs_lora/     --batch_size 1     --lr 1e-4     --epochs 100     --r 16     --alpha 16     --dropout 0.05
```

### ParÃ¡metros importantes:

| ParÃ¡metro | Significado |
|----------|-------------|
| `input_folder` | Carpeta con imÃ¡genes PNG/JPG |
| `output_dir` | Donde se guardarÃ¡n los pesos LoRA |
| `r` | DimensiÃ³n interna de LoRA |
| `alpha` | Escala de LoRA |
| `dropout` | Dropout aplicado a mÃ³dulos LoRA |
| `epochs` | Iteraciones de entrenamiento |
| `lr` | Learning rate |
| `device` | CPU o GPU |

**Salida esperada:**

```bash
outputs_lora/lora_weights.pth
```

---

# ğŸ” Inferencia con LoRA

Archivo: **inference_lora.py**

### EjecuciÃ³n:

```bash
python inference_lora.py     --image_path examples/chair.png     --lora_path outputs_lora/lora_weights.pth     --repo_root .
```

### Â¿QuÃ© hace el script?

1. Carga el modelo base TripoSR (`model.ckpt`)
2. Inyecta los mÃ³dulos LoRA (**igual que en el entrenamiento**)
3. Carga los pesos entrenados
4. Procesa la imagen â†’ genera el `scene_code`
5. Usa Marching Cubes para extraer la malla
6. Exporta:

```bash
mesh_lora.obj
```

---

## ğŸ“¦ Estructura del proyecto

```bash
TripoSR-LORA/
â”œâ”€â”€ fine_tuning.py
â”œâ”€â”€ inference_lora.py
â”œâ”€â”€ tsr/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ nerf_renderer.py   # Modificado con chunk_size
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ outputs_lora/
â”‚   â””â”€â”€ lora_weights.pth
â””â”€â”€ README.md
```

---

## ğŸ‘¨â€ğŸ’» AutorÃ­a

Proyecto desarrollado como parte del **Proyecto Final de Computer Vision**, Mauricio AndrÃ©s Manrique â€” Universidad del Rosario (2025).
