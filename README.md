# Fine Tuning LoRA aplicado a TripoSR

<a href="https://huggingface.co/stabilityai/TripoSR"><img src="https://img.shields.io/badge/üîó%20TripoSR-HuggingFace-orange"></a>
<a href="https://arxiv.org/pdf/2403.02151"><img src="https://img.shields.io/badge/üìÑ%20Paper%20TripoSR-ArXiv-B31B1B"></a>
<a href="/mnt/data/CVProjectPresent.pdf"><img src="https://img.shields.io/badge/üìò%20Informe%20del%20Proyecto-PDF-blue"></a>

---

## üìå Descripci√≥n

Este proyecto desarrolla un Fine-Tuning con LoRA sobre el modelo TripoSR para mejorar la reconstrucci√≥n 3D a partir de im√°genes espec√≠ficas.  
Para el entrenamiento se utiliz√≥ una peque√±a parte, equivalente a 1000 archivos ```.obj``` del gran conjunto de datos: **ABC Dataset** (https://deep-geometry.github.io/abc-dataset/), del cual se extrajeron las muestras empleadas en las pruebas y en el ajuste del modelo. Los pesos logrados fueron alojados en la carpeta ```wrights_lora/```.

### ¬øQu√© se modific√≥ exactamente con LoRA?

El entrenamiento LoRA se aplic√≥ sobre:

- **El backbone** del encoder de imagen de TripoSR.  
- Los **m√≥dulos de atenci√≥n**, espec√≠ficamente los valores **K, V y C** dentro de las capas *self-attention* y *cross-attention* del modelo.

Esto permite que el modelo aprenda nuevas variaciones de forma **sin modificar todos los pesos base**, manteniendo estable la arquitectura principal.

Durante el fine-tuning se inyectaron los m√≥dulos LoRA en:

- `transformer_blocks[i].attn1.to_q`
- `transformer_blocks[i].attn1.to_k`
- `transformer_blocks[i].attn1.to_v`
- `transformer_blocks[i].attn1.to_out.0`
- `transformer_blocks[i].attn2.to_q`
- `transformer_blocks[i].attn2.to_k`
- `transformer_blocks[i].attn2.to_v`
- `transformer_blocks[i].attn2.to_out.0`

(Ver l√≥gica en `fine_tuning.py` del proyecto).

---

## ‚öôÔ∏è Detalles t√©cnicos  
### Cambios realizados al modelo TripoSR original

La √∫nica modificaci√≥n directa hecha al c√≥digo fuente de TripoSR ocurri√≥ en:

```bash
tsr/models/nerf_renderer.py
```

### ¬øQu√© se cambi√≥?

Se a√±adi√≥ un par√°metro **`chunk_size`** para controlar la cantidad de rayos procesados en cada iteraci√≥n del renderizado NeRF.

### ¬øPor qu√© es necesario?

TripoSR extrae la malla usando **Marching Cubes**, que requiere muestrear la funci√≥n SDF sobre un grid 3D. Esto puede consumir **enormes cantidades de VRAM**.  
El `chunk_size` permite dividir este procesamiento en bloques m√°s peque√±os para:

- evitar *OOM errors* (out of memory),
- permitir el entrenamiento en GPUs de 24‚Äì48 GB de VRAM,
- mejorar la estabilidad del entrenamiento LoRA,
- mantener el *rendering pipeline* sin romper la arquitectura interna.

Esta modificaci√≥n **no altera la arquitectura del modelo**, solo la eficiencia computacional.

---

## üõ†Ô∏è Instalaci√≥n y configuraci√≥n del entorno

### ‚ö†Ô∏è Requisitos m√≠nimos de hardware
| Recurso | Valor m√≠nimo |
|--------|--------------|
| GPU | **CUDA 11.x**, ideal 11.4 |
| VRAM | **‚â• 25 GB** (para fine-tuning) |
| RAM | 16 GB |
| Sistema | Linux, CentOS7, Ubuntu 20.04 |
| Python | 3.9.x |

---

## üì• Instalaci√≥n paso a paso (Conda + CUDA + TorchMCubes)

### 1Ô∏è‚É£ Crear entorno conda  
*(El comando exacto depende del usuario)*

```bash
conda create -n TripoSR python=3.9
conda activate TripoSR
```

---

### 2Ô∏è‚É£ Instalar PyTorch compatible con CUDA 11.8

```bash
pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu118
```

---

### 3Ô∏è‚É£ Instalar dependencias del proyecto

```bash
pip install -r requirements.txt
```

---

### 4Ô∏è‚É£ Fijar NumPy a la versi√≥n correcta

```bash
pip install "numpy==1.26.4" --force-reinstall
python -c "import numpy as np; print('numpy', np.__version__)"
```

---

### 5Ô∏è‚É£ Instalar TorchMCubes

```bash
pip install --no-build-isolation "torchmcubes @ git+https://github.com/tatsy/torchmcubes.git"
```

Si falla:

```bash
pip install --upgrade pip
unzip torchmcubes
cd torchmcubes
pip install -e .
```

---

### 6Ô∏è‚É£ Instalar herramientas para compilaci√≥n

```bash
pip install -U pip setuptools wheel
pip install -U scikit-build-core ninja cmake
```

---

### 7Ô∏è‚É£ Cargar m√≥dulos del cl√∫ster (HPC)

```bash
module purge all
module load gnu9
module load cuda/11.4
```

---

### 8Ô∏è‚É£ Validaci√≥n final

```bash
python -c "import torch, torchmcubes, numpy as np; print('CUDA available?', torch.cuda.is_available()); print('ok torchmcubes, numpy', np.__version__)"
```

---

## üöÄ Uso del proyecto

A continuaci√≥n se explica c√≥mo ejecutar **fine_tuning.py** y luego **inference_lora.py**.

---

# üéØ Fine Tuning (Entrenamiento LoRA)

Archivo: **fine_tuning.py**

### Ejecuci√≥n general:

```bash
python fine_tuning.py     --input_folder ruta/a/imagenes/     --output_dir outputs_lora/     --batch_size 1     --lr 1e-4     --epochs 100     --r 16     --alpha 16     --dropout 0.05
```


### Sobre el funcionamiento de los dem√°s scripts del proyecto

**generate_mesh_triposr.py** genera las mallas que se usar√°n para evaluar (o comparar) el modelo base y el modelo fine-tuneado con LoRA. Se ejecuta de la siguiente forma:

```bash
# Modelo base
python generate_mesh_triposr.py \
  --images_dir ./images \
  --output_dir outputs/base_meshes \
  --pretrained_name_or_path . \
  --config_name config.yaml \
  --weight_name model.ckpt \
  --model_type base

# Modelo con LoRA
python generate_mesh_triposr.py \
  --images_dir ./images \
  --output_dir outputs/lora_meshes \
  --pretrained_name_or_path . \
  --config_name config.yaml \
  --weight_name model.ckpt \
  --model_type lora \
  --lora_weights weights_lora/lora_weights.pth
```
---
**data_processing.py** procesa las mallas ```.obj``` y genera las im√°genes multivista, m√°scaras, depth y par√°metros de c√°mara para el Fine-Tuning. Se ejecuta de la siguiente forma:
```bash
python data_processing.py \
  --objs_dir ./obj \
  --output_root ./dataFT \
  --img_size 512 \
  --yfov 50
```
---

**metricas.py** calcula las m√©tricas (Chamfer Distance y F-Score) para comparar el modelo base vs LoRA.
Se ejecuta as√≠:

```bash
python metricas_triposr.py \
  --gt_dir ./meshes_gt \
  --base_dir outputs/base_meshes \
  --lora_dir outputs/lora_meshes
```
---

### Par√°metros importantes:

| Par√°metro | Significado |
|----------|-------------|
| `input_folder` | Carpeta con im√°genes PNG/JPG |
| `output_dir` | Donde se guardar√°n los pesos LoRA |
| `r` | Dimensi√≥n interna de LoRA |
| `alpha` | Escala de LoRA |
| `dropout` | Dropout aplicado a m√≥dulos LoRA |
| `epochs` | Iteraciones de entrenamiento |
| `lr` | Learning rate |
| `device` | CPU o GPU |

**Salida esperada:**

```bash
outputs_lora/lora_weights.pth
```

---

# üîç Inferencia con LoRA

Archivo: **inference_lora.py**

### Ejecuci√≥n:

```bash
python inference_lora.py     --image_path <ruta de la imagen> --lora_path weights_lora/lora_weights.pth     --repo_root .
```

### ¬øQu√© hace el script?

1. Carga el modelo base TripoSR (`model.ckpt`)
2. Inyecta los m√≥dulos LoRA (**igual que en el entrenamiento**)
3. Carga los pesos entrenados
4. Procesa la imagen ‚Üí genera el `scene_code`
5. Usa Marching Cubes para extraer la malla
6. Exporta:

```bash
mesh_lora.obj
```

---

## üì¶ Estructura del proyecto

```bash
TripoSR-LORA/
‚îú‚îÄ‚îÄ fine_tuning.py
‚îú‚îÄ‚îÄ inference_lora.py
‚îú‚îÄ‚îÄ tsr/
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ nerf_renderer.py   # Modificado con chunk_size
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ outputs_lora/
‚îÇ   ‚îî‚îÄ‚îÄ lora_weights.pth
‚îî‚îÄ‚îÄ README.md
```

---

## üë®‚Äçüíª Autor√≠a

Proyecto desarrollado como parte del **Proyecto Final de Computer Vision**, Mauricio Andr√©s Manrique ‚Äî Universidad del Rosario (2025).
